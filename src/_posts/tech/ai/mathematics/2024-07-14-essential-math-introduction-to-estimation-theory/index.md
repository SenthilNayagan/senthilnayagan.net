---
title: "Essential Math for AI and ML: Introduction to Estimation Theory"
description: Estimation theory is like the detective work of data science. It equips us with methods to infer unknown parameters from observed data. Imagine estimating the average height in a city or the likelihood of a coin flip. Key techniques like Maximum Likelihood and Bayesian Estimation ensure our guesses are accurate and reliable. Used in fields from economics to engineering, estimation theory transforms raw data into meaningful insights. It’s the art and science of turning observations into actionable knowledge, guiding decisions in everyday life and complex industries alike. Dive into this fascinating world and become a data detective!
keywords: [estimation-theory, math-for-ai-ml, essential-math]
categories: [estimation-theory, math-for-ai-ml, essential-math]
coverImage: ./images/cover-image.webp
imageDescription: Old scholars in a grand study room, engaged in estimation.
imageCredits: Image generated by <b>DALL-E</b>.
# lastUpdated: 2024-07-14
draft: true
---

{% include "toc.md" %}

# What is estimation theory?

Estimation theory is a branch of mathematics and statistics that deals with the process of estimating the value of a parameter<a href="#ref-1"><sup id="back-to-1">1</sup></a> or a function from a set of noisy or uncertain data. In estimation theory, the goal is to find the best possible estimate of a parameter or a function based on a set of observations or measurements aka observed data. In other words, estimation theory is concerned with deriving estimates of parameters or functions based on observed data, which might be noisy or uncertain. The goal is to obtain the best possible estimate that reflects the underlying true value.

{% aside %}
**What does estimation theory offer?**

The estimation theory provide us with:

1. **Methods for estimating** the unknowns (model parameter, signals, etc.)
2. **Means for accessing** the "goodness" of the resulting estimates.
3. **Making confidence** statements about the true values.
{% endaside %}

## Approaches in estimation

1. **Minimizing the difference**
   - One common approach is to minimize the difference between the observed data and the predicted values, such as using least squares to find the line that best fits the data points.
2. **Maximizing the likelihood**
   - An alternative method is to maximize the likelihood that the observed data occurred given the estimated parameter or function. This technique is known as **maximum likelihood estimation** (**MLE**).

## Key concepts in estimation theory

There are several key concepts in estimation theory, including:

- **Estimator**: An estimator is a function that maps the observed data to an estimate of the parameter or function.
- **Bias**: Bias refers to the difference between the expected value of an estimator and the true value of the parameter or function.
- **Variance**: Variance refers to the spread or dispersion of an estimator around its expected value.
- **Consistency**: Consistency refers to the property of an estimator that its expected value converges to the true value of the parameter or function as the sample size increases.
- **Efficiency**: Efficiency refers to the property of an estimator that it has the smallest possible variance among all unbiased estimators.

## Different types of estimation

There are several types of estimation, including:

- **Point estimation**: Point estimation involves estimating a single value for the parameter or function.
- **Interval estimatio**n: Interval estimation involves estimating a range of values for the parameter or function.
- **Bayesian estimation**: Bayesian estimation involves using Bayes' theorem to update the probability distribution of the parameter or function based on the observed data.
- **Maximum likelihood estimation**: Maximum likelihood estimation involves finding the value of the parameter or function that maximizes the likelihood of the observed data.

## Common estimation techniques

Some common estimation techniques include:

- **Least squares estimation**: Least squares estimation involves minimizing the sum of the squared differences between the observed data and the predicted values.
- **Maximum likelihood estimation**: Maximum likelihood estimation involves finding the value of the parameter or function that maximizes the likelihood of the observed data.
- **Bayesian estimation**: Bayesian estimation involves using Bayes' theorem to update the probability distribution of the parameter or function based on the observed data.
- **Kalman filter estimation**: Kalman filter estimation involves using a recursive algorithm to estimate the state of a system based on noisy or uncertain data.

Having said that, estimation theory has many applications in various fields and is an essential tool for making informed decisions in many areas of science and engineering.

# Various mathematical notations uses in estimation theory

In estimation theory, various mathematical notations are used to represent data, parameters, estimators, and distributions. Here are some common notations along with their explanations:

## Data and samples

1. **x (Observed data, pronounced “x”)**:
   - A vector of observed/realized values from a sample.
   - Example: \\( x = (x_1, x_2, \ldots, x_n) \\)

2. **X (Random variables, pronounced “X”)**:
   - A vector of random variables.
   - Example: \\( X = (X_1, X_2, \ldots, X_n) \\)

## Parameters

1. **\\( \theta \\) (Parameter, pronounced “theta”)**:
   - A generic parameter of a probability distribution.
   - Example: \\( \theta \in \Theta \\)

2. **\\( \mu \\) (Mean, pronounced “mu”)**:
   - The mean of a distribution.

3. **\\( \sigma \\) (Standard deviation, pronounced “sigma”)**:
   - The standard deviation of a distribution.

4. **\\( \sigma^2 \\) (Variance, pronounced “sigma squared”)**:
   - The variance of a distribution.

5. **\\( p \\) (Probability, pronounced “p”)**:
   - The probability of success in a Bernoulli or binomial distribution.

## Estimators

1. **\\( \hat{\theta} \\) (Estimator of $ \theta $, pronounced “theta hat”)**:
   - An estimator of the parameter \\( \theta \\).
   - Example: \\( \hat{\theta} \\) is the sample mean used to estimate the population mean \\( \theta \\).

2. **\\( \hat{\mu} \\) (Estimator of $ \mu $, pronounced “mu hat”)**:
   - An estimator of the mean \\( \mu \\).

3. **\\( \hat{\sigma}^2 \\) (Estimator of $ \sigma^2 $, pronounced “sigma squared hat”)**:
   - An estimator of the variance \\( \sigma^2 \\).

## Probability and likelihood

1. **\\( P(X) \\) (Probability, pronounced “P of X”)**:
   - The probability of the random variable \\( X \\).

2. **\\( f(x|\theta) \\) (Probability density/mass function, pronounced “f of x given theta”)**:
   - The probability density function (PDF) or probability mass function (PMF) of \\( x \\) given parameter \\( \theta \\).
   - Example: \\( f(x|\theta) \\) for a normal distribution might be \\( f(x|\mu, \sigma^2) \\).

3. **\\( L(\theta|x) \\) (Likelihood function, pronounced “L of theta given x”)**:
   - The likelihood function of the parameter \\( \theta \\) given the observed data \\( x \\).
   - Example: \\( L(\theta|x) = f(x|\theta) \\) for the product of individual probabilities or densities.

4. **\\( \log L(\theta|x) \\) (Log-likelihood function, pronounced “log L of theta given x”)**:
   - The log-likelihood function, often used for simplification in calculations.

## Statistical inference

1. **\\( \mathcal{F} \\) (Family of distributions, pronounced “script F”)**:
   - A family of distributions.
   - Example: \\( \mathcal{F} = \{ f(x|\theta) | \theta \in \Theta \} \\)

2. **\\( \Theta \\) (Parameter space, pronounced “Theta”)**:
   - The parameter space, representing all possible values of \\( \theta \\).
   - Example: \\( \Theta = \mathbb{R} \\) for real-valued parameters.

3. **\\( E[X] \\) (Expected value, pronounced “E of X”)**:
   - The expected value of the random variable \\( X \\).

4. **\\( \text{Var}(X) \\) (Variance, pronounced “Variance of X”)**:
   - The variance of the random variable \\( X \\).

---

# Frequently asked questions (FAQs)

## What is a probability distribution?

A probability distribution is a mathematical function that describes the likelihood of different outcomes in a random experiment, such as tossing a coin or rolling a die. It describes the likelihood of various outcomes, which can include the possibility of the same result occurring multiple times. These likelihoods are often uncertain or probabilistic.

For example, let's say we're flipping a fair coin. The probability distribution of the outcome might look like this:

- Heads: 0.5 (or 50%)
- Tails: 0.5 (or 50%)

In this case, we can't predict the outcome with certainty because both heads and tails have the same probability of occurring (0.5 or 50%). The probability distribution tells us that the outcome is uncertain, and we can't know for sure what will happen.

It's important to note that a probability distribution means we can predict the likelihood of various outcomes, but we cannot predict the specific outcome of a single trial or event with certainty.

So, to summarize: The probability distribution provides a way to measure the uncertainty or randomness of an event or phenomenon, and we can use this information to make informed decisions or predictions.

## What is independent and identically distributed (iid or IID)?

In probability theory and statistics, a collection of random variables is said to be independent and identically distributed (IID) if:

1. **Each random variable has the same probability distribution as the others**: 
   - This means that every random variable in the collection follows the same *probability distribution*. In other words, they have the same statistical properties such as mean, variance, and distribution shape.
   - **Example**: Consider flipping a fair coin multiple times. Let $ X_1, X_2, \ldots, X_n $ represent the outcomes of each flip, where $ X_i = 1 $ if the flip is heads and $ X_i = 0 $ if the flip is tails. Each $ X_i $ follows the same Bernoulli distribution with $ P(X_i = 1) = 0.5 $ and $ P(X_i = 0) = 0.5 $.

2. **All random variables are mutually independent**:
   - This means that the outcome of any one random variable does not affect the outcome of any other random variable in the collection. There is no dependency between the random variables.
   - **Example**: Continuing with the coin flip example, the outcome of the first flip $ (X_1) $ does not influence the outcome of the second flip $ (X_2) $, and so on. Each flip is an independent event.

It's usually abbreviated as i.i.d., iid, or IID.

## What is parametric estimation?

Parametric estimation is a statistical technique used to estimate the value of a parameter<a href="#ref-1"><sup id="back-to-1">1</sup></a> (a number or a value) that describes a population<a href="#ref-2"><sup id="back-to-2">2</sup></a> or a process. In simple terms, it's like trying to figure out the exact value of a mysterious number that controls a certain phenomenon.

Imagine we're trying to estimate the average height of a group of people. We take a random sample of 100 people and measure their heights. We then use this data to estimate the average height of the entire group. This is an example of parametric estimation. In this case, the parameter is the average height of the group, and the data is the heights of the 100 people in the sample. The goal is to use the data to estimate the value of the parameter, which is the average height of the entire group.

Parametric estimation is different from non-parametric estimation, which is a technique used when we don't know the exact form of the distribution of the data. In parametric estimation, we assume that the data follows a specific distribution (such as a normal distribution), and then use the data to estimate the parameters of that distribution.

Here are some key points to keep in mind:

- Parametric estimation is used to estimate the value of a parameter that describes a population or a process.
- The data is used to estimate the value of the parameter.
- The goal is to use the data to make inferences about the population or process.
- Parametric estimation assumes that the data follows a specific distribution (such as a normal distribution).


<div class="references">
   <hr>
   <h2>Notes and references</h2>
   <ol>
      <!-- <li>Nil</li> -->
      <li id="ref-1">1. <strong>Parameter</strong>: A parameter in estimation theory refers to a characteristic or attribute of a system or process under study or modeling. Parameters are typically numerical values that describe the behavior, properties, or relationships of the system. Parameters are fixed and often unknown values that describe a certain aspect of the population. Consider them as the "hidden" or "latent" variables that control the system's behavior. Examples of parameters in different fields include mean (µ) (the average value of a population), variance (σ²) (the measure of variability or spread in a population), etc. In estimation theory, the goal is to estimate the values of these parameters from a set of observed data, often in the presence of noise or uncertainty. We can then use the estimated values of the parameters to make predictions, simulate system behavior, or guide decision-making. <a href="#back-to-1" class="back-to-note">↩</a>
      </li>
      <li id="ref-2">2. <strong>Population</strong>: In the context of parametric estimation, the population refers to the entire group or set of data that we're trying to make inferences about. For example, if we're trying to estimate the average height of a group of people, the population would be the entire group of people, not just the 100 people in our sample. In other words, the population is the entire universe of data that we're interested in, and the sample is a smaller subset of that universe that we're using to make inferences about the population. Here are some examples of populations: A population of students in a school, a population of people in a city, etc. <a href="#back-to-2" class="back-to-note">↩</a>
      </li>     
   </ol>
</div>
