---
title: "Starting with AI: A Beginner’s Journey into Artificial Intelligence (Part 1)"
description: Begin an exciting journey into the world of artificial intelligence. This beginner-friendly guide covers fundamental concepts, demystifies AI, and provides practical steps to get started.
keywords: [ai, artificial-intelligence]
categories: [ai, artificial-intelligence]
coverImage: ./images/cover-image.webp
imageDescription: An image depicting machine-based intelligence used in ancient times.
imageCredits: Image generated by <b>DALL-E</b>.
lastUpdated: 2024-07-06
draft: true
---

Welcome to the fascinating world of Artificial Intelligence (AI)! It's revolutionizing the way we live, work, and interact with the world. As we start this journey, it’s important to understand that AI is a broad and complex field with many different foundational concepts. Due to the sheer breadth and depth of AI, it’s challenging to encapsulate all the foundational elements in a single blog post.

To ensure a comprehensive and digestible learning experience, I’ve decided to split the introduction to AI into a series of blog posts. Each post will delve into specific aspects of AI, allowing us to explore the subject matter thoroughly and thoughtfully.

This blog post marks the beginning of our series, where we will start by understanding the basic concepts of AI, its types, and current developments. Stay tuned for the upcoming posts, where we’ll continue to unravel the intricacies of AI, step by step.

Let’s dive in and start our journey into the exciting realm of Artificial Intelligence!

---

{% include "toc.md" %}

# What is Artificial Intelligence?

At its core, Artificial Intelligence refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. These intelligent systems can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. The goal of AI is to create systems that can function autonomously and improve their performance over time through learning and adaptation.

## High-level steps involved in AI development

Creating an AI system involves several high-level steps, each crucial to developing a functional and effective AI solution. Here is an overview of these steps in the order they typically occur:

1. **Problem definition and goal setting**
   - Identify the specific problem we want to solve with AI.
   - Define clear and measurable goals for the AI system.
   - Determine the scope and constraints of the project.
2. **Data collection**
   - Gather relevant and high-quality data from various sources.
   - Ensure the data is comprehensive and representative of the problem domain.
   - Data can be collected from databases, APIs, web scraping, sensors, or manual entry
3. **Data preparation**
   - Clean the data to remove any inconsistencies, errors, or missing values.
   - Preprocess the data by normalizing, scaling, or encoding categorical variables.
   - Split the data into training, validation, and test sets to evaluate the AI model’s performance.
4. **Feature<a href="#ref-1"><sup id="back-to-1">1</sup></a> engineering**
   - Select and create meaningful features from the raw data that will be used as input for the AI model.
   - Transform and combine features to enhance the model’s predictive power.
   - Feature engineering is a critical step that can significantly impact the model’s performance.
5. **Model<a href="#ref-2"><sup id="back-to-2">2</sup></a> selection**
   - Choose the appropriate AI model or algorithm based on the problem type (e.g., classification, regression, clustering).
   - Evaluate models based on their suitability for the specific problem and data characteristics.
6. **Model training**
   - Train the selected AI model using the training data.
   - Optimize the model’s parameters<a href="#ref-3"><sup id="back-to-3">3</sup></a> and hyperparameters to improve its accuracy and performance.
   - Use techniques like cross-validation to ensure the model generalizes well to new data.
7. **Model evaluation**
   - Assess the model’s performance using the validation and test data sets.
   - Evaluate key metrics such as accuracy, precision, recall<a href="#ref-4"><sup id="back-to-4">4</sup></a>, F1-score<a href="#ref-5"><sup id="back-to-5">5</sup></a>, and others, depending on the problem.
   - Identify any potential issues like overfitting or underfitting and address them.
8. **Model deployment**
   - Deploy the trained AI model into a production environment where it can be used to make predictions or decisions.
   - Integrate the model with existing systems, applications, or workflows.
   - Ensure the deployment process includes monitoring and maintenance mechanisms.
9. **Model monitoring and maintenance**
   - Continuously monitor the AI model’s performance in the real world.
   - Update the model as needed based on new data, changing conditions, or performance degradation.
   - Implement feedback loops to retrain and improve the model over time.
10. **Iterative improvement**
    - AI development is an iterative process that involves continuous learning and improvement.
    - Regularly review and refine the model based on new insights, data, and technological advancements.
    - Iterate through the steps to enhance the AI system’s effectiveness and adapt to evolving requirements.

By following these high-level steps, we can develop and deploy AI systems in a step-by-step manner that addresses real-world problems and delivers meaningful results.

---

# Understanding the differences

Let's go over the key concepts in AI, such as models, features, and other essential elements to better understand how AI works.

## Artificial Intelligence (AI) vs. Machine Learning (ML)

The terms "Artificial Intelligence" (AI) and "Machine Learning" (ML)" are often used interchangeably, but they're not quite the same thing. Think of AI as the _grand quest_<a href="#ref-6"><sup id="back-to-6">6</sup></a> to create smart machines that can think and act like humans. Meanwhile, ML is a specialized toolkit within this quest, equipping machines with the ability to *learn and adapt from data*, much like how we humans evolve through experiences.

### Key Differences: AI vs. ML

1. Breadth
   - AI is the overarching discipline that includes all methods to make machines intelligent.
   - ML is a specific approach within AI that emphasizes the use of data to train models.
2. Techniques
   - AI includes a variety of methods beyond just ML, such as rule-based systems, search algorithms, and symbolic AI.
   - ML specifically involves statistical techniques and algorithms like decision trees, support vector machines, and neural networks.
3. Implementation
   - AI systems might use ML as one of their components but can also include other approaches to intelligence.
   - ML relies heavily on data and algorithms to learn patterns and make decisions without explicit programming for each task.
4. Applications
   - AI applications can be broader and more diverse, including anything from autonomous robotics to game playing to natural language understanding.
   - ML applications are often centered around tasks like predictive analytics, recommendation systems, image and speech recognition, and language translation.

## Machine Learning (ML)  vs. Deep Learning (DL)

Machine Learning (ML) and Deep Learning (DL) are both subsets of artificial intelligence (AI), but they differ in complexity, approach, and application.

<div class="scroll-x">
    <style>
        #table-1 {
            font-size: 14px;
        }
    </style>
    <table id="table-1">
        <colgroup>
            <col style="width: 50%;">
            <col style="width: 50%;">
        </colgroup>
        <thead>
            <tr>
                <th scope="col">Machine Learning (ML)</th>
                <th scope="col" class="numeric">Deep Learning (DL)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Definition</strong>: ML is a subset of AI that enables computers to learn from data and improve their performance over time without being explicitly programmed.</td>
                <td><strong>Definition</strong>: DL is a subset of ML that involves neural networks with many layers (hence “deep”) to model complex patterns in large amounts of data.</td>
            </tr>
            <tr>
                <td><strong>Algorithms</strong>: ML includes a variety of algorithms, such as: Supervised Learning (e.g., Linear Regression, Decision Trees, Support Vector Machines), Unsupervised Learning (e.g., K-Means Clustering, Principal Component Analysis), Reinforcement Learning (e.g., Q-Learning).</td>
                <td><strong>Algorithms</strong>: DL primarily uses neural network architectures, such as: Convolutional Neural Networks (CNNs) for image processing, Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks for sequential data, Generative Adversarial Networks (GANs) for generating new data samples, Transformer networks for natural language processing.</td>
            </tr>
            <tr>
                <td><strong>Data Representation</strong>: ML algorithms typically require structured data, and feature engineering is often necessary to transform raw data into a suitable format for learning.</td>
                <td><strong>Data Representation</strong>: DL can automatically discover representations from raw data, making it highly effective with unstructured data like images, audio, and text. It often requires large datasets for training.</td>
            </tr> 
            <tr>
                <td><strong>Model Complexity</strong>: ML models can range from simple to moderately complex. They typically involve fewer parameters than deep learning models.</td>
                <td><strong>Model Complexity</strong>: DL models are significantly more complex, involving millions of parameters. They require substantial computational power and often benefit from hardware accelerators like GPUs and TPUs.</td>
            </tr> 
            <tr>
                <td><strong>Interpretability</strong>: ML models are generally more interpretable and easier to understand compared to deep learning models. For example, decision trees and linear regression models provide clear insights into how predictions are made.</td>
                <td><strong>Interpretability</strong>: DL models are often considered black boxes due to their complexity, making them less interpretable than traditional ML models.</td>
            </tr> 
            <tr>
                <td><strong>Use Cases</strong>: Common applications include spam detection, recommendation systems, predictive maintenance, and more.</td>
                <td><strong>Use Cases</strong>: Common applications include image and speech recognition, natural language processing, autonomous driving, and more.</td>
            </tr>                                                   
        </tbody>
    </table>
</div>

<p align="center">
    <sup><b>Table 1: </b>Machine Learning (ML)  vs. Deep Learning (DL).</sup>
</p>

**Summary:**

- Machine Learning:
  - Broad category encompassing many types of algorithms.
  - Effective with structured data and requires feature engineering.
  - Generally simpler, more interpretable models.
- Deep Learning:
  - Subset of ML focusing on neural networks with many layers.
  - Excels with unstructured data and can automatically learn features.
  - More complex, less interpretable models requiring large datasets and computational resources.

Both ML and DL have their strengths and are suited to different types of problems. The choice between them depends on the specific application, the nature of the data, and the available resources.

---

# Key concepts

## What is a "model" in the context of AI and ML?

In the context of artificial intelligence (AI) and machine learning (ML), a "model" is a set of rules or patterns that a computer program uses to make predictions, classify data, or make decisions. Think of a model like a recipe for making a cake. The recipe tells us what ingredients to use, how to mix them together, and what temperature to bake the cake at. If we follow the recipe correctly, we'll get a delicious cake!

The rules or patterns are typically represented as mathematical equations or algorithms that are used to make predictions or decisions based on input data.

### Different types of models

There are many different types of models available in machine learning, each with its own strengths and weaknesses. Here are some of the most common types of models:

1. **Linear regression model**: A linear regression model predicts a continuous outcome based on input features (a feature is measurable property or variable or attribute).
2. **Logistic regression**: A logistic regression model predicts the probability of a binary outcome. 
3. **Decision tree model**: A decision tree model uses a tree-like structure of decisions to predict outcomes.
4. **Neural networks model**: A neural network consists of layers of interconnected neurons, where each connection has a weight, and each neuron has a bias.
5. **K-Means clustering model**: A k-Means clustering model partitions data into K clusters based on feature similarity.

**Does a model refer to an algorithm?** No, a model does not refer to an algorithm. They are related but distinct concepts. An algorithm is a set of rules or a procedure for solving a problem. It is the method or technique used to process data and *train a model*. Algorithms define how the data is analyzed and how the learning process is carried out. A model, on the other hand, *is the result of applying an algorithm to data*. It is a mathematical representation of patterns learned from training data. The model can then be used to make predictions or decisions based on new data.

## What is Retrieval-Augmented Generation (RAG)?

Retrieval-Augmented Generation (RAG) is a type of language model that combines the strengths of both retrieval-based and generation-based language models to create more powerful and accurate models for tasks like question answering, summarization, and other natural language processing tasks. In traditional language models, the model generates text from scratch, whereas in retrieval-based models, the model retrieves relevant text snippets from a database or a large corpus<a href="#ref-8"><sup id="back-to-8">8</sup></a> of documents.

Here’s how RAG works:

1. **Retrieval Component**: When a query is made, the model first retrieves a set of relevant documents or pieces of information from a pre-defined knowledge base or corpus. This is often done using information retrieval techniques like TF-IDF, BM25, or dense vector search with embeddings.

2. **Generation Component**: The retrieved documents are then passed along with the original query to a generative model. The generative model (like a transformer-based model) uses this additional context to produce a more accurate and informed response.

Having said that, RAG models use a hybrid approach. They first retrieve relevant text snippets from a database or corpus using a retrieval algorithm, and these retrieved snippets are then provided as input to a generation model, which generates new text that is influenced and informed by the retrieved snippets.

### Why is RAG essentially needed?

1.	**Enhanced context understanding**:
    - **Context-rich responses**: RAG models leverage external knowledge, leading to responses that are richer in context and more informative.
    - **Dynamic knowledge updates**: Instead of relying solely on pre-trained data, RAG can dynamically pull in the most relevant and up-to-date information, making it more flexible and current.

2. **Improved accuracy**:
    - **Fact-checking**: By incorporating retrieved documents, RAG models can verify facts and reduce the likelihood of generating incorrect or misleading information.
    - **Domain-specific knowledge**: For specialized queries, RAG can retrieve domain-specific documents that provide the necessary context, improving the accuracy of the generated content.
3. **Versatility**:
    - **Multiple applications**: RAG can be applied to various tasks such as question answering, summarization, translation, and more, making it a versatile tool in natural language processing.
    - **Adaptive learning**: RAG models can adapt to new topics or domains by updating the retrieval corpus, making them more adaptable to different use cases.
4. **Efficiency**:
    - **Resource utilization**: By retrieving only relevant information, RAG models can potentially reduce the computational resources needed compared to training a generative model with vast amounts of data.
    - **Focused generation**: The retrieval component narrows down the context, enabling the generative model to focus on producing high-quality responses based on the most pertinent information.

RAG represents a significant advancement in the field of natural language processing by combining the strengths of retrieval-based and generation-based models. It enhances the quality, accuracy, and contextual relevance of generated responses, making it a powerful tool for a wide range of applications. The integration of dynamic retrieval mechanisms ensures that RAG models can provide up-to-date and precise information, addressing some of the limitations of traditional generative models.

<!-- ---

# Frequently asked questions (FAQs)

## Q1?

TODO -->

<div class="references">
  <hr>
  <h2>Notes and references</h2>
  <ol>
  <!-- <li>Nil</li> -->
    <li id="ref-1">1. <strong>Feature</strong>: A feature, also known as an <em>attribute</em> or <em>variable</em>, is an individual measurable property or characteristic of a phenomenon being observed. In the context of machine learning, features are the inputs used by models to make predictions. They play a crucial role in determining the performance and accuracy of a model. Features can be thought of as the independent variables that the model uses to learn patterns and relationships within the data. There are various types of features: 1. Numerical features (takes specific integer value, such as the count of sales, etc.), 2. Categorical feature (represent categories without any inherent order. For example, colors [red, green, blue], types of fruits [apple, banana, cherry]), 3. Binary feature (have only two possible values, often represented as 0 and 1. For example, gender [male, female], outcome [success, failure]), 4. Time-based feature (represents temporal data. For example, timestamps, dates, and time intervals). <a href="#back-to-1" class="back-to-note">↩</a>
    </li>
    <li id="ref-2">2. <strong>Model</strong>: A model is a mathematical representation of a process or a system that is used to make predictions or decisions based on input data. It captures the patterns and relationships within the data, allowing it to generalize and make accurate predictions on new, unseen data. Models are the core components of AI systems, transforming data into actionable insights. <a href="#back-to-2" class="back-to-note">↩</a>
    </li>
    <li id="ref-3">3. <strong>Model's parameters</strong> are the variables within the model that are adjusted during the training process to minimize the error between the model’s predictions and the actual outcomes. Parameters are learned from the data. They are internal variables within a machine learning model that are adjusted during the training process. These parameters define the model’s structure and behavior, influencing how it maps input data to output predictions. The primary goal of training a model is to optimize these parameters to minimize the error between the model’s predictions and the actual target values. <a href="#back-to-3" class="back-to-note">↩</a>
    </li>
    <li id="ref-4">4. <strong>Recall</strong>: Recall is like being thorough when finding specific items in a large set. Imagine we’re looking for apples in a big fruit basket. Recall measures how good we are at finding all the apples in the basket. If there are 100 apples in the basket, and we find 80 of them, our recall is high because we managed to find a large portion of the apples. <a href="#back-to-4" class="back-to-note">↩</a>
    </li>  
    <li id="ref-5">5. <strong>F1-Score</strong>: F1-Score balances thoroughness (recall) and accuracy (precision). It’s like balancing finding all the apples and making sure you’re only picking apples, not mistaking other fruits for apples. Precision measures how accurate we are when we say I’ve found an apple. If we sometimes pick oranges thinking they’re apples, our precision is lower. So recall is about finding as many of the true positive cases as possible. <a href="#back-to-5" class="back-to-note">↩</a>
    </li>         
    <li id="ref-6">6. <strong>Grand quest</strong>: A quest in general is a journey or a mission undertaken to achieve a specific goal or objective. It can be a physical or metaphorical journey, and it often involves overcoming challenges, facing obstacles, and progressing towards a desired outcome. A grand quest is a particularly significant, ambitious, or epic quest that often requires extraordinary effort, dedication, and perseverance. In this context of AI vs. ML, I used the term "grand quest" metaphorically to describe the ambitious and significant pursuit of creating intelligent machines in the field of AI. <a href="#back-to-6" class="back-to-note">↩</a>
    </li>
    <li id="ref-7">7. <strong>Centroids</strong>: In k-means clustering, a centroid is the mean (average) position of all the points in a cluster. It is the point that minimizes the sum of the squared distances between itself and all the points in the cluster. Centroids act as the center of each cluster. During the k-means clustering process, the algorithm iteratively adjusts the centroids to better fit the data. <a href="#back-to-7" class="back-to-note">↩</a>
    </li> 
    <li id="ref-8">8. <strong>Corpus</strong>: The term "corpus" or "large corpus" refers to a substantial collection of documents or text data that the retrieval component of the system uses to find relevant information. <a href="#back-to-8" class="back-to-note">↩</a>
    </li>          
  </ol>
</div>